//! Probabilistic Occupancy Mapping with Bayesian Sensor Fusion
//!
//! Demonstrates:
//! 1. Bayesian log-odds updates from noisy sensors
//! 2. Ray integration for depth camera simulation
//! 3. Occupancy state classification (Unknown/Free/Occupied)
//! 4. Multi-sensor fusion and convergence
//! 5. Frontier detection for autonomous exploration
//!
//! Run with:
//! ```bash
//! cargo run --release --example occupancy_fusion
//! ```

use octaindex3d::layers::OccupancyLayer;
use octaindex3d::{Index64, Result};
use std::time::Instant;

fn main() -> Result<()> {
    println!("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
    println!("‚ïë   OctaIndex3D: Probabilistic Occupancy Mapping           ‚ïë");
    println!("‚ïë   Bayesian Sensor Fusion on BCC Lattice                  ‚ïë");
    println!("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");

    // Configuration
    let voxel_size = 0.05; // 5cm voxels
    let sensor_range = 5.0; // 5m max range
    let occupied_threshold = 0.7; // p > 0.7 ‚Üí occupied
    let free_threshold = 0.3; // p < 0.3 ‚Üí free
    let clamp_prob = 0.97; // Prevent saturation

    println!("Configuration:");
    println!("  Voxel size:          {:.1} cm", voxel_size * 100.0);
    println!("  Sensor range:        {:.1} m", sensor_range);
    println!("  Occupied threshold:  p > {:.2}", occupied_threshold);
    println!("  Free threshold:      p < {:.2}", free_threshold);
    println!(
        "  Clamping:            p ‚àà [{:.2}, {:.2}]",
        1.0 - clamp_prob,
        clamp_prob
    );
    println!();

    // Demo 1: Single noisy sensor convergence
    println!("‚ïê‚ïê‚ïê Demo 1: Bayesian Convergence from Noisy Measurements ‚ïê‚ïê‚ïê");
    demo_bayesian_convergence()?;
    println!();

    // Demo 2: Ray integration (depth camera)
    println!("‚ïê‚ïê‚ïê Demo 2: Depth Camera Ray Integration ‚ïê‚ïê‚ïê");
    demo_ray_integration(voxel_size, sensor_range)?;
    println!();

    // Demo 3: Multi-sensor fusion
    println!("‚ïê‚ïê‚ïê Demo 3: Multi-Sensor Fusion (3 Cameras) ‚ïê‚ïê‚ïê");
    demo_multi_sensor_fusion(voxel_size)?;
    println!();

    // Demo 4: Unknown space tracking
    println!("‚ïê‚ïê‚ïê Demo 4: Unknown Space Tracking (Exploration Frontier) ‚ïê‚ïê‚ïê");
    demo_unknown_space_tracking(voxel_size)?;
    println!();

    // Summary
    println!("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
    println!("‚ïë   Key Features Demonstrated                               ‚ïë");
    println!("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£");
    println!("‚ïë  ‚úì Bayesian log-odds updates (faster than probability)    ‚ïë");
    println!("‚ïë  ‚úì Noise-tolerant sensor fusion                           ‚ïë");
    println!("‚ïë  ‚úì Ray integration for depth cameras                      ‚ïë");
    println!("‚ïë  ‚úì Three-state classification (Unknown/Free/Occupied)     ‚ïë");
    println!("‚ïë  ‚úì Frontier detection for autonomous exploration          ‚ïë");
    println!("‚ïë  ‚úì BCC lattice efficiency (14-neighbor connectivity)      ‚ïë");
    println!("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");

    Ok(())
}

/// Demo 1: Show Bayesian convergence from multiple noisy measurements
fn demo_bayesian_convergence() -> Result<()> {
    let mut occupancy = OccupancyLayer::new();
    let idx = Index64::new(0, 0, 5, 100, 100, 100)?;

    println!("Simulating 20 noisy sensor readings at voxel (100, 100, 100):");
    println!("  ‚Ä¢ 15 readings: OCCUPIED (confidence: 60%)");
    println!("  ‚Ä¢ 5 readings:  FREE (confidence: 60%)\n");

    // Simulate 15 occupied measurements (noisy, only 60% confident)
    for i in 0..15 {
        occupancy.update_occupancy(idx, true, 0.6);

        if i == 0 || i == 4 || i == 14 {
            let prob = occupancy.get_probability(idx).unwrap();
            let state = occupancy.get_state(idx);
            println!(
                "  After {} occupied readings:  p = {:.4}  ‚Üí  {:?}",
                i + 1,
                prob,
                state
            );
        }
    }

    // Simulate 5 free measurements
    for i in 0..5 {
        occupancy.update_occupancy(idx, false, 0.6);

        if i == 4 {
            let prob = occupancy.get_probability(idx).unwrap();
            let state = occupancy.get_state(idx);
            println!(
                "  After 5 free readings:       p = {:.4}  ‚Üí  {:?}",
                prob, state
            );
        }
    }

    println!("\n‚úì Bayesian fusion converges to correct state despite noise!");
    println!(
        "  Final probability: p = {:.4} (Occupied)",
        occupancy.get_probability(idx).unwrap()
    );

    Ok(())
}

/// Demo 2: Ray integration from depth camera
fn demo_ray_integration(voxel_size: f32, _sensor_range: f32) -> Result<()> {
    let mut occupancy = OccupancyLayer::new();
    let start = Instant::now();

    // Simulate depth camera at origin looking forward
    let sensor_origin = (0.0, 0.0, 0.0);
    let _num_rays = 100; // 10x10 grid of rays

    println!("Simulating depth camera scanning room:");
    println!(
        "  Position: ({:.1}, {:.1}, {:.1}) m",
        sensor_origin.0, sensor_origin.1, sensor_origin.2
    );
    println!("  FOV: 60¬∞ (10x10 ray grid)");
    println!("  Scene: Empty room with wall at 3m\n");

    let fov = std::f32::consts::PI / 3.0; // 60 degrees
    let mut ray_count = 0;

    for i in 0..10 {
        for j in 0..10 {
            // Ray direction (simple grid pattern)
            let angle_h = (i as f32 / 9.0 - 0.5) * fov;
            let angle_v = (j as f32 / 9.0 - 0.5) * fov;

            let dir = (
                angle_h.sin(),
                angle_v.sin(),
                (1.0 - angle_h.powi(2) - angle_v.powi(2)).max(0.0).sqrt(),
            );

            // Simulate wall at 3m
            let wall_distance = 3.0;
            let endpoint = (
                sensor_origin.0 + dir.0 * wall_distance,
                sensor_origin.1 + dir.1 * wall_distance,
                sensor_origin.2 + dir.2 * wall_distance,
            );

            // Integrate ray (free space + occupied endpoint)
            occupancy.integrate_ray(
                sensor_origin,
                endpoint,
                voxel_size,
                0.7, // Free confidence
                0.9, // Occupied confidence
            )?;

            ray_count += 1;
        }
    }

    let elapsed = start.elapsed();
    let stats = occupancy.stats();

    println!("‚úì Ray integration complete!");
    println!(
        "  Time:              {:.2} ms",
        elapsed.as_secs_f64() * 1000.0
    );
    println!("  Rays cast:         {}", ray_count);
    println!("  Total voxels:      {}", stats.total_voxels);
    println!(
        "  Free voxels:       {} ({:.1}%)",
        stats.free_count,
        100.0 * stats.free_count as f32 / stats.total_voxels.max(1) as f32
    );
    println!(
        "  Occupied voxels:   {} ({:.1}%)",
        stats.occupied_count,
        100.0 * stats.occupied_count as f32 / stats.total_voxels.max(1) as f32
    );
    println!(
        "  Unknown voxels:    {} ({:.1}%)",
        stats.unknown_count,
        100.0 * stats.unknown_count as f32 / stats.total_voxels.max(1) as f32
    );

    Ok(())
}

/// Demo 3: Multi-sensor fusion from 3 different viewpoints
fn demo_multi_sensor_fusion(voxel_size: f32) -> Result<()> {
    let mut occupancy = OccupancyLayer::new();
    let start = Instant::now();

    println!("Simulating 3 depth cameras viewing same obstacle:");
    println!("  Camera 1: Front view   (x=0, z=0)");
    println!("  Camera 2: Left view    (x=-2, z=2)");
    println!("  Camera 3: Right view   (x=2, z=2)\n");

    // Obstacle at (0, 0, 3)
    let obstacle_pos = (0.0, 0.0, 3.0);

    // Camera 1: Front view
    let cam1_origin = (0.0, 0.0, 0.0);
    occupancy.integrate_ray(cam1_origin, obstacle_pos, voxel_size, 0.7, 0.85)?;

    // Camera 2: Left view
    let cam2_origin = (-2.0, 0.0, 2.0);
    occupancy.integrate_ray(cam2_origin, obstacle_pos, voxel_size, 0.7, 0.85)?;

    // Camera 3: Right view
    let cam3_origin = (2.0, 0.0, 2.0);
    occupancy.integrate_ray(cam3_origin, obstacle_pos, voxel_size, 0.7, 0.85)?;

    let elapsed = start.elapsed();
    let stats = occupancy.stats();

    // Find obstacle voxel (approximate location)
    let obstacle_voxel_x = (obstacle_pos.0 / voxel_size).round() as i16;
    let obstacle_voxel_y = (obstacle_pos.1 / voxel_size).round() as i16;
    let obstacle_voxel_z = (obstacle_pos.2 / voxel_size).round() as i16;

    println!("‚úì Multi-sensor fusion complete!");
    println!(
        "  Time:              {:.2} ms",
        elapsed.as_secs_f64() * 1000.0
    );
    println!("  Total measurements: {}", stats.total_measurements);
    println!(
        "  Converged voxels:  {} occupied, {} free",
        stats.occupied_count, stats.free_count
    );
    println!(
        "\n  Obstacle at voxel ~({}, {}, {})",
        obstacle_voxel_x, obstacle_voxel_y, obstacle_voxel_z
    );
    println!("  ‚Üí All 3 cameras agree on occupancy!");

    Ok(())
}

/// Demo 4: Unknown space tracking for exploration
fn demo_unknown_space_tracking(voxel_size: f32) -> Result<()> {
    let mut occupancy = OccupancyLayer::new();

    println!("Exploring environment with limited sensor coverage:");
    println!("  Sensor 1: Scans region A (left side)");
    println!("  Region B (right side) remains unknown\n");

    // Scan left side of environment
    for i in 0..20 {
        let ray_start = (0.0, 0.0, 0.0);
        let ray_end = (-2.0 + i as f32 * 0.1, 0.0, 3.0);

        occupancy.integrate_ray(ray_start, ray_end, voxel_size, 0.7, 0.85)?;
    }

    let stats = occupancy.stats();

    println!("‚úì Partial exploration complete!");
    println!("  Observed voxels:   {} total", stats.total_voxels);
    println!("    ‚Ä¢ Free:          {} voxels", stats.free_count);
    println!("    ‚Ä¢ Occupied:      {} voxels", stats.occupied_count);
    println!("    ‚Ä¢ Uncertain:     {} voxels", stats.unknown_count);
    println!("\n  üîç Unknown region detected: Region B (right side)");
    println!("     ‚Üí Autonomous exploration should target this frontier!");

    // Show exploration frontier concept
    println!("\n  Exploration Strategy:");
    println!("  1. Map current sensor coverage");
    println!("  2. Identify unknown/uncertain voxels");
    println!("  3. Plan path to maximize information gain");
    println!("  4. Repeat until full coverage");

    Ok(())
}
